<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html lang="en">
<head>
    <title>Project 4 - Image Warping and Mosaicing</title>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"/>
    <link rel="stylesheet" href="assets/css/main.css"/>

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
          }
        });
    </script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
            type="text/javascript"></script>
</head>
<body class="is-preload">

<!-- Wrapper -->
<div id="wrapper">

    <!-- Main -->
    <div id="main">
        <div class="inner">

            <!-- Header -->
            <header id="header">
                <a href="index.html" class="logo"><strong>Project 4</strong> Image Warping and Mosaicing</a>
            </header>

            <!-- Banner -->
            <section id="pictures">
                <div class="content">
                    <header>
                        <h1>Shoot the Pictures<br/>
                        </h1>
                    </header>
                    <p>
                        In this project, most of the images are taken from a iPhone 13 Pro.
                        Some of the images are taken with a digital camera.
                    </p>
                    <p>
                        Here are some examples of the images used in this project.
                    </p>

                    <div class="box alt">
                        <div class="row gtr-50 gtr-uniform">
                            <div class="col-4"><span class="image fit"><img
                                    src="images/data/crater_cropped/crater_cropped%20(1).png" alt=""/></span></div>
                            <div class="col-4"><span class="image fit"><img
                                    src="images/data/crater_cropped/crater_cropped%20(2).png" alt=""/></span></div>
                            <div class="col-4"><span class="image fit"><img
                                    src="images/data/crater_cropped/crater_cropped%20(3).png" alt=""/></span></div>
                            <!-- Break -->

                            <div class="col-3"><span class="image fit"><img src="images/data/mpc_lab/mpc_lab%20(1).jpg"
                                                                            alt=""></span></div>
                            <div class="col-3"><span class="image fit"><img src="images/data/mpc_lab/mpc_lab%20(2).jpg"
                                                                            alt=""></span></div>
                            <div class="col-3"><span class="image fit"><img src="images/data/mpc_lab/mpc_lab%20(3).jpg"
                                                                            alt=""></span></div>
                            <div class="col-3"><span class="image fit"><img src="images/data/mpc_lab/mpc_lab%20(4).jpg"
                                                                            alt=""></span></div>
                            <!--                            <div class="col-3"><span class="image fit"><img src="images/data/mpc_lab/mpc_lab%20(5).jpg" alt=""></span></div>-->

                            <!-- Break -->
                            <div class="col-6"><span class="image fit"><img
                                    src="images/data/yosemite/yosemite%20(1).jpg" alt=""></span></div>
                            <div class="col-6"><span class="image fit"><img
                                    src="images/data/yosemite/yosemite%20(2).jpg" alt=""></span></div>

                            <!-- Break -->
                            <div class="col-6"><span class="image fit"><img
                                    src="images/data/new_mexico/new_mexico%20(1).jpg" alt=""></span></div>
                            <div class="col-6"><span class="image fit"><img
                                    src="images/data/new_mexico/new_mexico%20(2).jpg" alt=""></span></div>
                        </div>
                    </div>
                    <p>
                        Shout out to my partner <a href="https://www.instagram.com/yilun.photos/">Yilun</a> for
                        providing
                        the amazing photo at Meteor Crater, Arizona.
                        Go check out his other amazing photos!
                    </p>
                </div>
            </section>

            <section id="homography">
                <div class="content">
                    <header>
                        <h1>Recover Homographies<br/></h1>
                    </header>
                </div>
                <h2>How It Works</h2>
                <p>
                    Similar to <a href="../../proj3/home/index.html#midway">Project 3</a>, we need to find the best warp
                    between two images.
                </p>
                <p>
                    The goal is to find $$\mathbf{H} = \begin{bmatrix}a & b & c \\ d & e & f \\ g & h & 1\end{bmatrix}$$
                    such that $$\mathbf{H} = \mathrm{arg} \min_\mathbf{H} \sum_{(\mathbf{x}, \mathbf{x'}) \in
                    \mathcal{D}} \Vert \mathbf{Hx} -
                    \mathbf{x'}\Vert_2^2$$
                    where $\mathbf{x} = \begin{bmatrix}x & y & 1\end{bmatrix}^T$ and $\mathbf{x'} = \begin{bmatrix}wx' &
                    wy' & w\end{bmatrix}^T$.

                    Here, $\begin{bmatrix} x & y \end{bmatrix}$ and $\begin{bmatrix} x' & y' \end{bmatrix}$ are the
                    coordinates of the feature points in the source and destination images.
                    $w$ is the scaling factor.
                    $\mathcal{D}$ denotes the set of pairs of feature points in the two images.
                </p>
                <p>
                    We can rewrite this into a least squares problem on the parameters in $\mathbf{H}$.
                    For each pair of feature point $\mathbf{x}_i$ and $\mathbf{x}_i'$,
                    $$\underbrace{\begin{bmatrix} x_i & y_i & 1 & 0 & 0 & 0 & -x_i x_i' & -y_i x_i' \\ 0 & 0 & 0 & x_i &
                    y_i
                    & 1 & -x_i y_i' & -y_i y_i'\end{bmatrix}}_{P_i}
                    \begin{bmatrix}a \\ b \\ c \\ d \\ e \\ f \\ g \\ h\end{bmatrix} = \underbrace{\begin{bmatrix}x_i'
                    \\
                    y_i'\end{bmatrix}}_{v_i}$$
                </p>
                <p>
                    Stack $P_i$'s and $v_i$'s vertically, and we get a classical least squares problem, whose solution
                    is
                    given by $(P^T P)^{-1} P^T v$.
                </p>


                <h2 id="labeling">Defining correspondences</h2>
                <p>
                    Much like Project 3, we need to manually label the key features of the images before we can find the
                    homography.
                    Note that the images are labeled pairwise, so the features selected in each pair can be different,
                    even though they are taken from the same scene.
                </p>
                <p>
                    This is a laborious process, especially if the image chain is long.
                    As an example, below are the manually selected feature pairs of the Meteor Crater photos, with
                    feature points marked as <strong><span style="color: red">red</span></strong> dots.
                </p>
                <figure class="image fit">
                    <img src="images/outputs/crater_cropped/crater_cropped%20(1)_crater_cropped%20(2)_manually_annotated.png"
                         alt="">
                    <img src="images/outputs/crater_cropped/crater_cropped%20(2)_crater_cropped%20(3)_manually_annotated.png"
                         alt="">
                </figure>
            </section>

            <section id="rectify">
                <header class="content">
                    <h1>Image Rectification</h1>
                </header>
                <p>
                    One straightforward way to test the algorithm is image rectification.
                </p>
                <p>
                    Below is an image of a checkerboard and the location of the vertices of the middle 6x6 squares
                    (annotated with <strong><span style="color: green">green</span></strong> points).
                </p>
                <p>
                    We want to warp the image such that the vertices form a perfect square.
                    The desired location of the annotated points in the warped image are marked in <strong><span
                        style="color: red">red</span></strong> points.
                </p>
                <p>
                    The estimated region after the warp is highlighted with its vertices marked in
                    <strong><span style="color: blue">blue</span></strong> points.
                </p>
                <figure class="image fit">
                    <img src="images/outputs/checker_board_annotated.png" alt="">
                    <figcaption style="text-align: center">Annotated checker board and estimated warp result.
                    </figcaption>
                </figure>

                <p>
                    And here is the result of actually warping the entire image.
                </p>
                <figure class="image fit">
                    <img src="images/outputs/checker_board_warped.png" alt="">
                    <figcaption style="text-align: center">Warped checker board. Note the canvas was enlarged just
                        enough to keep both the original and warped image. This will be useful in blending images after
                        warping.
                    </figcaption>
                </figure>

                <p>
                    Below is another example.
                </p>
                <div class="box alt">
                    <div class="row gtr-50 gtr-uniform">
                        <div class="col-4">
                            <figure class="image fit">
                                <img src="images/data/Yilun.png" alt=""/>
                                <figcaption style="text-align: center">Yilun giving a talk.</figcaption>
                            </figure>
                        </div>
                        <div class="col-4">
                            <figure class="image fit">
                                <img src="images/outputs/Yilun_annotated.png" alt="">
                                <figcaption style="text-align: center">Annotation and the desired warp.</figcaption>
                            </figure>
                        </div>
                        <div class="col-4">
                            <figure class="image fit">
                                <img src="images/outputs/Yilun_warped.png" alt="">
                                <figcaption style="text-align: center">Warped image.</figcaption>
                            </figure>
                        </div>
                    </div>
                </div>
                <figure class="image fit">
                    <img src="images/outputs/Yilun_slides.png" alt=""/>
                    <figcaption style="text-align: center">
                        Closer look of Yilun's slides after rectification. Super cool work!
                    </figcaption>
                </figure>
            </section>

            <section id="blending">
                <div class="content">
                    <header>
                        <h1>
                            Blending the Images into a Mosaic<br/>
                        </h1>
                    </header>
                    <p>
                        With the feature points from manual annotation, we can recover the homography between two images
                        and recursively blend them into a growing mosaic.
                    </p>
                    <p>
                        Note that the homography can be accumulated, and therefore warping from image $A \rightarrow C$
                        can be achieved by the composition of $A \rightarrow B$ then $B \rightarrow C$.
                        Utilizing this fact, we first label each pair of adjacent images and get the estimated
                        homography matrix.
                        Then, we warp all images towards the center image.
                    </p>
                    <p>
                        Below are the step-by-step process of warping.
                    </p>
                    <h3 id="crater-manual">1. Meteor Crater Natural Landmark (photo by Yilun Ma)</h3>
                    <figure class="image fit">
                        <img src="images/outputs/crater_cropped/crater_cropped_mosaic_stage_1.png" alt="">
                        <figcaption style="text-align: center">Warping and blending the left image to the center.
                        </figcaption>
                    </figure>
                    <figure class="image fit">
                        <img src="images/outputs/crater_cropped/crater_cropped_mosaic_stage_2.png" alt="">
                        <figcaption style="text-align: center">Warping and blending blend the right image to the
                            previous result.
                        </figcaption>
                    </figure>

                    <p>
                        So far, we're just taking the average between the overlapping area, and the boundary of the
                        original images are very clearly visible.
                        To get smoother blending, we adopt Lowe's two-band blending technique, where we create a simple
                        two-level pyramid of the image, and use a smooth alpha channel to blend the low frequency and a
                        binary alpha channel for the high-frequency.
                    </p>
                    <p>
                        Below is the comparison between the results.
                        With two-band blending, the edges are gone, and the details of the center image are sharper.
                        However, this blending technique still left a faint shadow in the corners, which is discernible
                        if the color is monotonous and the exposure between photos are different.
                    </p>

                    <div class="box alt">
                        <div class="row gtr-50 gtr-uniform">
                            <div class="col-6">
                                <figure class="image fit">
                                    <img src="images/outputs/crater_cropped/crater_cropped_mosaic_stage_2_result_average.png"
                                         alt=""/>
                                    <figcaption style="text-align: center">Average mixture.</figcaption>
                                </figure>
                            </div>
                            <div class="col-6">
                                <figure class="image fit">
                                    <img src="images/outputs/crater_cropped/crater_cropped_auto_mosaic_stage_2_result.png"
                                         alt="">
                                    <figcaption style="text-align: center">Two-band blending.</figcaption>
                                </figure>
                            </div>
                        </div>
                    </div>
                    <h2>More results</h2>
                    <h3 id="marina-manual">2. San Francisco from Berkeley Marina on a Cloudy Day</h3>
                    <h4>Original Images</h4>
                    <div class="box alt">
                        <div class="row gtr-50 gtr-uniform">
                            <div class="col-4">
                                <figure class="image fit">
                                    <img src="images/data/marina/marina%20(1).jpg" alt=""/>
                                </figure>
                            </div>
                            <div class="col-4">
                                <figure class="image fit">
                                    <img src="images/data/marina/marina%20(2).jpg" alt=""/>
                                </figure>
                            </div>
                            <div class="col-4">
                                <figure class="image fit">
                                    <img src="images/data/marina/marina%20(3).jpg" alt=""/>
                                </figure>
                            </div>
                        </div>
                    </div>

                    <h4>Annotating and Pre-warping</h4>
                    <div class="box alt">
                        <div class="row gtr-50 gtr-uniform">
                            <div class="col-6">
                                <figure class="image fit">
                                    <img src="images/outputs/marina/marina%20(1)_annotated.png" alt=""/>
                                </figure>
                            </div>
                            <div class="col-6">
                                <figure class="image fit">
                                    <img src="images/outputs/marina/marina%20(3)_annotated.png" alt=""/>
                                </figure>
                            </div>
                        </div>
                    </div>
                    <p>Remember that the middle image, marina (2), is the reference and therefore doesn't warp! </p>

                    <h4>Warping and Blending</h4>
                    <figure class="image fit">
                        <img src="images/outputs/marina/marina_mosaic_stage_1.png" alt="">
                        <figcaption style="text-align: center">Warping and blending the right image to the center.
                        </figcaption>
                    </figure>
                    <figure class="image fit">
                        <img src="images/outputs/marina/marina_mosaic_stage_2.png" alt="">
                        <figcaption>Warping and blending the left image to the previous result.</figcaption>
                    </figure>

                    <h4>Final Result</h4>
                    <figure class="image fit">
                        <img src="images/outputs/marina/marina_mosaic_stage_2_result.png" alt="">
                    </figure>

                    <p>
                        <strong>Interesting fact</strong>: This set of images turned out very hard for the automatic
                        stitching algorithm.
                        One possible reason is that there are very few significant features in the majority of the
                        image.
                        Plus, the water and the sky are not entirely stationary!
                        This only worked by putting most of the feature points on the buildings, which seems
                        insignificant in the sense of corners.
                    </p>

                    <h3 id="nm-manual">3. Petroglyph National Monument, New Mexico</h3>
                    <h4>Original Images</h4>
                    <div class="box alt">
                        <div class="row gtr-50 gtr-uniform">
                            <div class="col-6">
                                <figure class="image fit">
                                    <img src="images/data/new_mexico/new_mexico%20(1).jpg" alt=""/>
                                </figure>
                            </div>
                            <div class="col-6">
                                <figure class="image fit">
                                    <img src="images/data/new_mexico/new_mexico%20(2).jpg" alt=""/>
                                </figure>
                            </div>
                        </div>
                    </div>

                    <h4>Annotating and Pre-warping</h4>
                    <figure class="image fit">
                        <img src="images/outputs/new_mexico/new_mexico%20(1)_annotated.png" alt="">
                    </figure>

                    <h4>Warping and Blending</h4>
                    <figure class="image fit">
                        <img src="images/outputs/new_mexico/new_mexico_mosaic_stage_1.png" alt="">
                    </figure>

                    <h4>Final Result</h4>
                    <figure class="image fit">
                        <img src="images/outputs/new_mexico/new_mexico_mosaic_stage_1_result.png" alt="">
                    </figure>

                    <p>
                        <strong>Spoiler:</strong> Note that there is very little overlap between the two images, so the
                        error in the annotation has a much more significant impact on the result.
                        In the later section, we'll see the automatic stitching does a much more precise job than I did.
                    </p>
                </div>
            </section>

            <section id="second">
                <header class="content">
                    <h1>Feature Matching and Auto-stitching</h1>
                </header>
                <p>
                    Instead of manually labeling the images, we seek ways to automatically find interesting features
                    and find correspondences among them.
                </p>
                <p>
                    The second part of the project is about the algorithm to achieve this.
                </p>

                <h2 id="harris">Harris Corner Detector</h2>
                <p>
                    From the first part of the project, we learn that corners can be used as easily identifiable
                    features.
                    Here, we use the <a href="https://docs.opencv.org/4.x/dc/d0d/tutorial_py_features_harris.html">Harris
                    interest point detector</a> to find all the corners of an image.
                </p>
                <p>
                    Below is the Harris corner measure of the checkerboard image.
                </p>
                <figure class="image fit">
                    <img src="images/data/checker_board.jpg" alt="">
                    <figcaption style="text-align: center">The checker board image.</figcaption>
                </figure>
                <figure class="image fit">
                    <img src="images/outputs/checker_board_harris_normalized.png" alt="">
                    <figcaption style="text-align: center">Harris corner measure of the <a
                            href="images/data/checker_board.jpg">checker board image</a>.
                        Pay close attention and you'll see an array of brighter dots. Those are the vertices of the
                        squares!
                    </figcaption>
                </figure>
                <figure class="image fit">
                    <img src="images/outputs/checker_board_harris_corner_scatter.png" alt="">
                    <figcaption style="text-align: center">Harris corners.</figcaption>
                </figure>

                <p>
                    The result has been filtered to only keep pixels whose corner response is larger than some
                    threshold.
                    However, this is clearly far from enough.
                </p>

                <h2 id="anms">Adaptive Non-Maximal Suppression (ANMS)</h2>
                <p>
                    One idea is to keep only the pixels with the largest corner response.
                    However, <a href="https://ieeexplore.ieee.org/document/1467310">Brown et al.</a> pointed out that
                    this leads to an imbalance in the spatial distribution of
                    feature points.
                    Instead, we adopt Adaptive Non-Maximal Suppression (ANMS) to select $N$ points that has the largest
                    corner response within the radius of $r$, where $r$ is maximized across the entire image.
                </p>
                <p>
                    Below is the result of applying ANMS on the checker board image with $N = 60$.
                    We can see from this example that the result of ANMS are indeed the vertices of the squares on the
                    board.
                    Also, some of the vertices are not selected because they're would have been too close to their
                    neighbors, which shows that ANMS is effective in ensuring the points are spatially well-separated
                    from each other.
                </p>
                <figure class="image fit">
                    <img src="images/outputs/checker_board_harris_random.png" alt="">
                </figure>

                <h2 id="descriptor">Feature Descriptor Extraction</h2>
                <p>
                    With the Harris corner detector and the ANMS algorithm, we can already automatically extract
                    interesting features from images.
                    The next step is to match between them.
                </p>
                <p>
                    Following Brown's paper, we crop out a 40x40 window around each feature point, and downsample them
                    to 8x8 patches.
                    Below are example of patches that are sampled from the checker board image.
                </p>
                <figure class="image fit">
                    <img src="images/outputs/checker_board_descriptors.png" alt="">
                    <figcaption style="text-align: center">
                        Feature descriptors examples from the checker board image.
                        They may look alike because of the repetitive nature of the checker board pattern.
                        This will no longer be the case for our images!
                    </figcaption>
                </figure>

                <h2 id="matching">Feature Matching</h2>
                <p>
                    Finally, we will compare the patches from the two images we're trying to stitch together and find
                    matches.
                </p>
                <p>
                    Assume our goal is to find the best match in the target image $B$ for each patch in the source image
                    $A$.
                    We start by finding the top 2 matches for all patches in the source image $A$.
                    Here we apply Lowe's thresholding criteria and compare the ratio between the error of 1-NN/2-NN.
                    For good matches, this ratio should be low.
                    In Brown's paper, the optimal threshold for the squared error between 1-NN/2-NN appears to be 0.1,
                    but with the <a href="#ransac">RANSAC</a> algorithm, it's acceptable to be more lenient with
                    thresholding at this step.
                </p>
                <p>
                    Here is one example with two images taken from Yosemite.
                </p>
                <figure class="image fit">
                    <img src="images/outputs/yosemite/yosemite%20(1)_yosemite%20(2)_Feature_Matching.png" alt="">
                    <figcaption style="text-align: center">
                        Feature matching between two images taken at Yosemite.
                        The transparent <strong><span style="color: green">green</span></strong> points are all feature
                        points selected by the Harris corner detector and ANMS.
                        The <strong><span style="color: red">red</span></strong> points are the matched points selected
                        through matching the feature descriptors.
                    </figcaption>
                </figure>

                <h2 id="ransac">Random Sample Consensus (RANSAC)</h2>
                <p>
                    From the example above, we can see most of the points are indeed valid matches.
                    However, there are still outliers, which is undesirable because least squares optimization is
                    sensitive to outliers.
                </p>
                <p>
                    To find the best homography $H$, we implemented <a
                        href="https://en.wikipedia.org/wiki/Random_sample_consensus">Random Sample Consensus
                    (RANSAC)</a>, an outlier detection algorithm.
                    In RANSAC, we iteratively select four random pairs of points and <a href="#homography">compute the
                    homography $H$</a>.
                    Then, we apply the transformation on all feature points $\mathbf{x}$ in the source image $A$, and
                    count the number of near matches with the points in image $B$.
                    The goal is to find the homography that leads to the most number of near matches. In other words,
                    $$H^{*} = \mathrm{arg} \max_H \vert \{ (\mathbf{x}, \mathbf{x'}) \vert \Vert \mathbf{Hx} -
                    \mathbf{x'} \Vert < \epsilon \}\vert$$
                </p>
                <p>
                    In the example above, after 100000 iterations, the best set of points found by the RANSAC algorithm
                    is as follows.
                </p>
                <figure class="image fit">
                    <img src="images/outputs/yosemite/yosemite%20(1)_yosemite%20(2)_Feature_Matching_with_RANSAC.png"
                         alt="">
                    <figcaption style="text-align: center">
                        The best set of feature pairs found by RANSAC. $\epsilon = 1$.
                    </figcaption>
                </figure>

                <h2 id="auto-mosaic">Producing Mosaics</h2>
                <p>
                    Now that we have the feature pairs, we can use <a href="#blending">the same warping procedure</a>
                    to stitch the images together.
                </p>
                <figure class="image fit">
                    <img src="images/outputs/yosemite/yosemite%20(1)_annotated.png" alt="">
                    <figcaption style="text-align: center">
                        Annotated image and expected warping.
                    </figcaption>
                </figure>
                <figure class="image fit">
                    <img src="images/outputs/yosemite/yosemite_mosaic_stage_1_result.png" alt="">
                    <figcaption style="text-align: center">
                        Result of Auto-stitching the Yosemite images.
                    </figcaption>
                </figure>

                <h2 id="results">More results</h2>
                <h3 id="nm-auto">2. Petroglyph National Monument, New Mexico</h3>
                <h4>Original Images</h4>
                <div class="row gtr-50 gtr-uniform">
                    <div class="col-6">
                        <figure class="image fit">
                            <img src="images/data/new_mexico/new_mexico%20(1).jpg" alt="">
                        </figure>
                    </div>
                    <div class="col-6">
                        <figure class="image fit">
                            <img src="images/data/new_mexico/new_mexico%20(2).jpg" alt="">
                        </figure>
                    </div>
                </div>

                <h4>Matched points with RANSAC</h4>
                <figure class="image fit">
                    <img src="images/outputs/new_mexico/new_mexico%20(1)_new_mexico%20(2)_feature_matching.png" alt="">
                </figure>

                <h4>Automatic Stitching (and comparison with manual results)</h4>
                <figure class="image fit">
                    <img src="images/outputs/new_mexico/new_mexico_auto_mosaic_stage_1_result.png" alt="">
                    <figcaption style="text-align: center">
                        Result of <strong>automatic</strong> stitching.
                    </figcaption>
                </figure>
                <figure class="image fit">
                    <img src="images/outputs/new_mexico/new_mexico_mosaic_stage_1_result.png" alt="">
                    <figcaption style="text-align: center">
                        Result of <strong>manual</strong> stitching.
                    </figcaption>
                </figure>
                <p>
                    Look closely in the overlapping area.
                    There is very little misalignment in the automatic stitching result, whereas the overlapping area is
                    a bit blurry in the manual result.
                    This shows that the automatic labeling and feature matching did a very precise job in locating and
                    matching the features.
                </p>

                <h3 id="crater-auto">3. Meteor Crater National Landmark (photo by Yilun Ma)</h3>
                <h4>Original Images</h4>
                <div class="box alt">
                    <div class="row gtr-50 gtr-uniform">
                        <div class="col-4">
                            <figure class="image fit">
                                <img src="images/data/crater_cropped/crater_cropped%20(1).png" alt=""/>
                            </figure>
                        </div>
                        <div class="col-4">
                            <figure class="image fit">
                                <img src="images/data/crater_cropped/crater_cropped%20(2).png" alt=""/>
                            </figure>
                        </div>
                        <div class="col-4">
                            <figure class="image fit">
                                <img src="images/data/crater_cropped/crater_cropped%20(3).png" alt=""/>
                            </figure>
                        </div>
                    </div>
                </div>

                <h4>Matched points with RANSAC</h4>
                <figure class="image fit">
                    <img src="images/outputs/crater_cropped/crater_cropped%20(1)_crater_cropped%20(2)_feature_matching.png"
                         alt="">
                </figure>
                <figure class="image fit">
                    <img src="images/outputs/crater_cropped/crater_cropped%20(2)_crater_cropped%20(3)_feature_matching.png"
                         alt="">
                </figure>

                <h4>Automatic Stitching (and comparison with manual results)</h4>
                <figure class="image fit">
                    <img src="images/outputs/crater_cropped/crater_cropped_auto_mosaic_stage_1_result.png" alt="">
                    <figcaption style="text-align: center">
                        2-image <strong>automatic</strong> mosaic.
                    </figcaption>
                </figure>
                <figure class="image fit">
                    <img src="images/outputs/crater_cropped/crater_cropped_auto_mosaic_stage_2_result.png" alt="">
                    <figcaption style="text-align: center">
                        3-image <strong>automatic</strong> mosaic.
                    </figcaption>
                </figure>
                <figure class="image fit">
                    <img src="images/outputs/crater_cropped/crater_cropped_mosaic_stage_2_result.png" alt="">
                    <figcaption style="text-align: center">
                        3-image <strong>manual</strong> mosaic.
                    </figcaption>
                </figure>

                <p>
                    Similar to the example above, manual stitching is less precise than automatic stitching.
                    While both results are quite acceptable, there are less ghosting in the automatically stitched
                    image.
                </p>


                <h3 id="mpc-auto">4. Stitching together more images: MPC Lab</h3>
                <h4>Original Images</h4>
                <div class="box alt">
                    <div class="row gtr-50 gtr-uniform">
                        <div class="col-4">
                            <figure class="image fit">
                                <img src="images/data/mpc_lab/mpc_lab%20(1).jpg" alt=""/>
                            </figure>
                        </div>
                        <div class="col-4">
                            <figure class="image fit">
                                <img src="images/data/mpc_lab/mpc_lab%20(2).jpg" alt=""/>
                            </figure>
                        </div>
                        <div class="col-4">
                            <figure class="image fit">
                                <img src="images/data/mpc_lab/mpc_lab%20(3).jpg" alt=""/>
                            </figure>
                        </div>
                        <div class="col-6">
                            <figure class="image fit">
                                <img src="images/data/mpc_lab/mpc_lab%20(4).jpg" alt=""/>
                            </figure>
                        </div>
                        <div class="col-6">
                            <figure class="image fit">
                                <img src="images/data/mpc_lab/mpc_lab%20(5).jpg" alt=""/>
                            </figure>
                        </div>
                    </div>
                </div>

                <h4>Matched points with RANSAC</h4>
                <div class="box alt">
                    <div class="row gtr-50 gtr-uniform">
                        <div class="col-12">
                            <figure class="image fit">
                                <img src="images/outputs/mpc_lab_5/mpc_lab%20(1)_mpc_lab%20(2)_feature_matching.png"
                                     alt=""/>
                            </figure>
                        </div>
                        <div class="col-12">
                            <figure class="image fit">
                                <img src="images/outputs/mpc_lab_5/mpc_lab%20(2)_mpc_lab%20(3)_feature_matching.png"
                                     alt=""/>
                            </figure>
                        </div>
                        <div class="col-12">
                            <figure class="image fit">
                                <img src="images/outputs/mpc_lab_5/mpc_lab%20(3)_mpc_lab%20(4)_feature_matching.png"
                                     alt=""/>
                            </figure>
                        </div>
                        <div class="col-12">
                            <figure class="image fit">
                                <img src="images/outputs/mpc_lab_5/mpc_lab%20(4)_mpc_lab%20(5)_feature_matching.png"
                                     alt=""/>
                            </figure>
                        </div>
                    </div>
                </div>

                <h4>Automatic Stitching</h4>
                <div class="box alt">
                    <div class="row gtr-50 gtr-uniform">
                        <div class="col-12">
                            <figure class="image fit">
                                <img src="images/outputs/mpc_lab_5/mpc_lab_auto_mosaic_stage_1_result.png" alt=""/>
                                <figcaption style="text-align: center">
                                    2-image mosaic.
                                </figcaption>
                            </figure>
                        </div>
                        <div class="col-12">
                            <figure class="image fit">
                                <img src="images/outputs/mpc_lab_5/mpc_lab_auto_mosaic_stage_2_result.png" alt=""/>
                                <figcaption style="text-align: center">
                                    3-image mosaic.
                                </figcaption>
                            </figure>
                        </div>
                        <div class="col-12">
                            <figure class="image fit">
                                <img src="images/outputs/mpc_lab_5/mpc_lab_auto_mosaic_stage_3_result.png" alt=""/>
                                <figcaption style="text-align: center">
                                    4-image mosaic.
                                </figcaption>
                            </figure>
                        </div>
                        <div class="col-12">
                            <figure class="image fit">
                                <img src="images/outputs/mpc_lab_5/mpc_lab_auto_mosaic_stage_4_result.png" alt=""/>
                                <figcaption style="text-align: center">
                                    5-image mosaic.
                                </figcaption>
                            </figure>
                        </div>
                        <p>
                            All images are mostly aligned at first sight, but note how the ghosting effect becomes
                            increasingly significant as more images are stitched together, especially in the middle
                            where there's the most overlapping.
                            Furthermore, we noticed that the center of the image is well-aligned, but the ghosting
                            becomes increasingly prominent near the upper and lower edges.
                        </p>
                        <p>
                            One suspected reason is the distortion caused by the lenses, which is the most significant
                            near the edges.
                            Another reason is that the images were not taken with an iPhone without a tripod, meaning
                            the center of projection is not exactly the same.
                        </p>
                    </div>
                </div>
            </section>
            <section id="conclusion">
                <header class="content">
                    <h1>Concluding Thoughts</h1>
                </header>
                <p>
                    The coolest thing I learned from this project is RANSAC.
                    This is a perfect example of how the collective wisdom can surpass that of an expert.
                    Also, this also gave me new inspirations on how to identify outliers to get better data.
                </p>
            </section>

            <section>
                <header class="content">
                    <h2>Reference</h2>
                    <ul>
                        <li>
                            <a href="https://docs.opencv.org/4.x/dc/d0d/tutorial_py_features_harris.html">Harris
                                Interest Point Detector</a>.
                        </li>
                        <li>
                            <a href="https://ieeexplore.ieee.org/document/1467310">M. Brown, R. Szeliski and S. Winder,
                                "Multi-image matching using multi-scale oriented
                                patches," 2005 IEEE Computer Society Conference on Computer Vision and Pattern
                                Recognition
                                (CVPR'05), San Diego, CA, USA, 2005, pp. 510-517 vol. 1, doi: 10.1109/CVPR.2005.235.</a>
                        </li>
                    </ul>

                    HTML template: <a href="https://html5up.net/editorial">Editorial by HTML5UP</a>
                </header>
            </section>
        </div>
    </div>

    <!-- Sidebar -->
    <div id="sidebar">
        <div class="inner">
            <!-- Menu -->
            <nav id="menu">
                <header class="major">
                    <h2>Menu</h2>
                </header>
                <ul>
                    <li>
                        <span class="opener">Part I</span>
                        <ul>
                            <li><a href="#pictures">Shoot the Pictures</a></li>
                            <li><a href="#homography">Recover Homographies</a></li>
                            <li><a href="#rectify">Image Rectification</a></li>
                            <li><a href="#blending">Blending Images into Mosaics</a></li>
                            <li>
                                <span class="opener">More Manual Stitching Results</span>
                                <ul>
                                    <li><a href="#marina-manual">San Francisco</a></li>
                                    <li><a href="#nm-manual">Petroglyph National Monument</a></li>
                                </ul>
                            </li>
                        </ul>
                    </li>
                    <li>
                        <span class="opener">Part II</span>
                        <ul>
                            <li><a href="#harris">Harris Corner Detector</a></li>
                            <li><a href="#anms">ANMS</a></li>
                            <li><a href="#descriptor">Feature Descriptors</a></li>
                            <li><a href="#matching">Feature Matching</a></li>
                            <li><a href="#ransac">RANSAC</a></li>
                            <li><a href="#auto-mosaic">Producing Mosaics</a></li>
                            <li>
                                <span class="opener">More Auto-stitching Results</span>
                                <ul>
                                    <li><a href="#nm-auto">Petroglyph National Monument</a></li>
                                    <li><a href="#crater-auto">Meteor Crater National Landmark</a></li>
                                    <li><a href="#mpc-auto">MPC Lab</a></li>
                                </ul>
                            </li>
                        </ul>
                    </li>
                    <li><a href="#conclusion">Concluding Thoughts</a></li>
                </ul>
            </nav>

            <!-- Section -->
            <section>
                <header class="major">
                    <h2>Author</h2>
                </header>
                <p>Shengfan Cao</p>
                <p>Ph.D. student in Mechanical Engineering</p>
                <p>Lab Affiliation: Model Predictive Control Lab</p>
                <ul class="contact">
                    <li class="icon solid fa-envelope"><a href="#">shengfan_cao@berkeley.edu</a></li>
                    <li class="icon solid fa-phone">(510) 946-0740</li>
                </ul>
            </section>
        </div>
    </div>

</div>

<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>

</body>
</html>